{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Detection using OpenCV\n",
    "\n",
    "**Aprroach/Algorithms** used:\n",
    "1. This project uses LBPH (Local Binary Patterns Histograms) Algorithm to detect faces. It labels the pixels of an image by thresholding the neighborhood of each pixel and considers the result as a binary number.\n",
    "2. LBPH uses 4 parameters:\n",
    "* Radius: the radius is used to build the circular local binary pattern and represents the radius around the \n",
    "central pixel. \n",
    "* Neighbors : the number of sample points to build the circular local binary pattern. \n",
    "* Grid X : the number of cells in the horizontal direction. \n",
    "* Grid Y : the number of cells in the vertical direction. \n",
    "3. The model built is trained with the faces with tag given to them and later on, the machine is given a test data and machine decides the correct label for it.\n",
    "\n",
    "**How to use:**\n",
    "1. Create a directory in your pc and name it (say project)\n",
    "2. Create two python files named `create_data.py` and `face_recognition.py`, copy the first and second source code in it respectively.\n",
    "3. Copy `haarcascade_frontalface_default.xml` to the project directory, you can get it in OpenCV or from [here](https://github.com/vschs007/flask-realtime-face-detection-opencv-python/blob/master/haarcascade_frontalface_default.xml) .\n",
    "4. You are ready to now run the following codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating database\n",
    "# It captures images and stores them in datasets\n",
    "# folder under the folder name of sub_data\n",
    "import cv2, sys, numpy, os\n",
    "haar_file = 'haarcascade_frontalface_default.xml'\n",
    " \n",
    "# All the faces data will be\n",
    "#  present this folder\n",
    "datasets = 'datasets' \n",
    " \n",
    " \n",
    "# These are sub data sets of folder,\n",
    "# for my faces I've used my name you can\n",
    "# change the label here\n",
    "sub_data = 'vivek'    \n",
    " \n",
    "path = os.path.join(datasets, sub_data)\n",
    "if not os.path.isdir(path):\n",
    "    os.mkdir(path)\n",
    " \n",
    "# defining the size of images\n",
    "(width, height) = (130, 100)   \n",
    " \n",
    "#'0' is used for my webcam,\n",
    "# if you've any other camera\n",
    "#  attached use '1' like this\n",
    "face_cascade = cv2.CascadeClassifier(haar_file)\n",
    "webcam = cv2.VideoCapture(0)\n",
    " \n",
    "# The program loops until it has 30 images of the face.\n",
    "count = 1\n",
    "while count < 30:\n",
    "    (_, im) = webcam.read()\n",
    "    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 4)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(im, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        face = gray[y:y + h, x:x + w]\n",
    "        face_resize = cv2.resize(face, (width, height))\n",
    "        cv2.imwrite('% s/% s.png' % (path, count), face_resize)\n",
    "    count += 1\n",
    "     \n",
    "    cv2.imshow('OpenCV', im)\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code should be run after the model has been trained for the faces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It helps in identifying the faces\n",
    "import cv2, sys, numpy, os\n",
    "size = 4\n",
    "haar_file = 'haarcascade_frontalface_default.xml'\n",
    "datasets = 'datasets'\n",
    "\n",
    "# Part 1: Create fisherRecognizer\n",
    "print('Recognizing Face Please Be in sufficient Lights...')\n",
    "\n",
    "# Create a list of images and a list of corresponding names\n",
    "(images, labels, names, id) = ([], [], {}, 0)\n",
    "for (subdirs, dirs, files) in os.walk(datasets):\n",
    "\tfor subdir in dirs:\n",
    "\t\tnames[id] = subdir\n",
    "\t\tsubjectpath = os.path.join(datasets, subdir)\n",
    "\t\tfor filename in os.listdir(subjectpath):\n",
    "\t\t\tpath = subjectpath + '/' + filename\n",
    "\t\t\tlabel = id\n",
    "\t\t\timages.append(cv2.imread(path, 0))\n",
    "\t\t\tlabels.append(int(label))\n",
    "\t\tid += 1\n",
    "(width, height) = (130, 100)\n",
    "\n",
    "# Create a Numpy array from the two lists above\n",
    "(images, labels) = [numpy.array(lis) for lis in [images, labels]]\n",
    "\n",
    "# OpenCV trains a model from the images\n",
    "# NOTE FOR OpenCV2: remove '.face'\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "model.train(images, labels)\n",
    "\n",
    "# Part 2: Use fisherRecognizer on camera stream\n",
    "face_cascade = cv2.CascadeClassifier(haar_file)\n",
    "webcam = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\t(_, im) = webcam.read()\n",
    "\tgray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\tfaces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\tfor (x, y, w, h) in faces:\n",
    "\n",
    "\t\tcv2.rectangle(im, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "\t\tface = gray[y:y + h, x:x + w]\n",
    "\t\tface_resize = cv2.resize(face, (width, height))\n",
    "\n",
    "\t\t# Try to recognize the face\n",
    "\t\tprediction = model.predict(face_resize)\n",
    "\t\tcv2.rectangle(im, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "\n",
    "\t\tif prediction[1]<500:\n",
    "\t\t\tcv2.putText(im, '% s - %.0f' % (names[prediction[0]], prediction[1]), (x-10, y-10), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0))\n",
    "\t\telse:\n",
    "\t\t\tcv2.putText(im, 'not recognized', (x-10, y-10), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0))\n",
    "\n",
    "\tcv2.imshow('OpenCV', im)\n",
    "\t\n",
    "\tkey = cv2.waitKey(10)\n",
    "\tif key == 27:\n",
    "\t\tbreak\n",
    "\n",
    "\tcv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
